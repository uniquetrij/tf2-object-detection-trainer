{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf2_object_detection_trainer_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BRrgnMs6l4Vz",
        "kMaH3-fBGsNG",
        "UK8D6FZ1qu_7",
        "4MBfTBWpHxZr",
        "coH2J-cYkVdz",
        "SxhcHyU8tuV5",
        "fjhqMCVIt0Q2",
        "QdotsqMWM8oJ",
        "iTXnls1fezFi",
        "hMginc7nT3mo",
        "s0nuR4KAWgZG"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD7Yq_-ey1il",
        "cellView": "form"
      },
      "source": [
        "#@title Give a name to your project\n",
        "TARGET = \"object-detection\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRmMYWCC3NUx",
        "cellView": "form"
      },
      "source": [
        "#@title Where to get your annotated dataset from?\n",
        "DATASET_DOWNLOAD_LINK = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLHM_lNd2716",
        "cellView": "form"
      },
      "source": [
        "#@title Where to get your pretrained model from?\n",
        "MODEL_DOWNLOAD_LINK = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcXt_tsTCr6F"
      },
      "source": [
        "DRIVE_MOUNTPOINT = \"/content/drive\"\n",
        "\n",
        "def mount_drive():\n",
        "    from google.colab import drive\n",
        "    drive.mount(DRIVE_MOUNTPOINT, force_remount=True)\n",
        "\n",
        "_ = !cat {DRIVE_MOUNTPOINT}\n",
        "if 'No such file or directory' in _[0]:\n",
        "    mount_drive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRrgnMs6l4Vz"
      },
      "source": [
        "# Workspace Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdJrLEwQZNhJ"
      },
      "source": [
        "WORKSPACE = \"tf2-object-detection-trainer\"\n",
        "\n",
        "%mkdir -p /content/{WORKSPACE}\n",
        "%cd /content/{WORKSPACE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yu8Z3ntkup0"
      },
      "source": [
        "!pip install python-util tf_slim==1.1.0 lvis==0.5.3 tensorflow-addons==0.12.1 #scipy==1.6.1 pyyaml==5.4.1 gin-config==0.4.0 pandas==1.2.2 matplotlib==3.3.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfM2rVjfbbKT"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models tensorflow/models 2> /dev/null\n",
        "!(cd tensorflow/models;git checkout 73ce096)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTIUllZLkNw2"
      },
      "source": [
        "!wget https://github.com/protocolbuffers/protobuf/releases/download/v3.13.0/protoc-3.13.0-linux-x86_64.zip -c\n",
        "!unzip -u protoc-3.13.0-linux-x86_64.zip -d protoc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdzRqiGFkkGr"
      },
      "source": [
        "from os import environ as export\n",
        "_ = !pwd\n",
        "export['PATH'] += ':' + _[0] + '/protoc/bin'\n",
        "!(cd tensorflow/models/research;protoc object_detection/protos/*.proto --python_out=.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGVosjt2k2Y8"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi cocoapi 2> /dev/null\n",
        "!(cd cocoapi;git checkout 8c9bcc3)\n",
        "!(cd cocoapi/PythonAPI/; printf 'conda activate {ENV_NAME}\\nmake\\n' | bash -i )\n",
        "!cp -r ./cocoapi/PythonAPI/pycocotools ./tensorflow/models/research/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7N5lAZkrnEH"
      },
      "source": [
        "_ = !pwd\n",
        "TF_OD_PATH = _[0]+'/tensorflow/models/research'\n",
        "\n",
        "from os import environ as export\n",
        "\n",
        "export['PYTHONPATH']=TF_OD_PATH+'/:'\n",
        "export['PYTHONPATH']+=TF_OD_PATH+'/../:'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMZ3od1FGoYD"
      },
      "source": [
        "!python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMaH3-fBGsNG"
      },
      "source": [
        "# Directory Structure Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TTwrFNPGpxl"
      },
      "source": [
        "%mkdir -p /content/{WORKSPACE}/targets\n",
        "%cd /content/{WORKSPACE}/targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WBrUf_rpJGA"
      },
      "source": [
        "ANNOTATIONS = 'annotations'\n",
        "EXPORTED = 'exported-models'\n",
        "IMAGES = 'images'\n",
        "TEST_DATA = 'test'\n",
        "TRAIN_DATA = 'train'\n",
        "LABEL_MAP = 'label_map.pbtxt'\n",
        "MODELS = 'models'\n",
        "PRETRAINED = '.pre-trained-models'\n",
        "INFERENCE = 'inference'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uANz4hkYpOBl"
      },
      "source": [
        "!mkdir -p {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{ANNOTATIONS}\n",
        "!mkdir -p {TARGET}/{ANNOTATIONS}\n",
        "\n",
        "!echo \"\" >> {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{ANNOTATIONS}/{LABEL_MAP}\n",
        "!ln -sf {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{ANNOTATIONS}/{LABEL_MAP} {TARGET}/{ANNOTATIONS}/{LABEL_MAP}\n",
        "\n",
        "!mkdir -p {TARGET}/{IMAGES}/{TEST_DATA}\n",
        "!mkdir -p {TARGET}/{IMAGES}/{TRAIN_DATA}\n",
        "\n",
        "!mkdir -p {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{EXPORTED}\n",
        "!mkdir -p {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{MODELS}\n",
        "\n",
        "!ln -sn {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{EXPORTED} {TARGET}/{EXPORTED} \n",
        "!ln -sn {DRIVE_MOUNTPOINT}/MyDrive/colab/{WORKSPACE}/{TARGET}/{MODELS} {TARGET}/{MODELS}\n",
        "\n",
        "!mkdir -p {PRETRAINED}\n",
        "!mkdir -p /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK8D6FZ1qu_7"
      },
      "source": [
        "# Training Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfrcsWMeH4Qp"
      },
      "source": [
        "def import_data():\n",
        "    !rm -rf {TARGET}/{IMAGES}/dataset\n",
        "\n",
        "    if DATASET_DOWNLOAD_LINK.endswith('.git'):\n",
        "        !mkdir {TARGET}/{IMAGES}/dataset/\n",
        "        !git clone {DATASET_DOWNLOAD_LINK} {TARGET}/{IMAGES}/dataset/\n",
        "\n",
        "    elif DATASET_DOWNLOAD_LINK.endswith('.tar.gz'):\n",
        "        !wget {DATASET_DOWNLOAD_LINK} -O {TARGET}/{IMAGES}/dataset.tar.gz -c\n",
        "        !tar -zxvf {TARGET}/{IMAGES}/dataset.tar.gz -C {TARGET}/{IMAGES} --one-top-level\n",
        "    \n",
        "    _ = ! echo {TARGET}/{IMAGES}/dataset/\n",
        "    export[\"dataset\"]=_[0]\n",
        "    !cd $dataset && find . -type f -exec sh -c 'new=$(echo \"{}\" | sed \"s/\\.\\///\" | tr \"/\" \"-\" | tr \" \" \"_\"); mv \"{}\" \"../$new\"' \\;\n",
        "    !rm -rf dataset*\n",
        "\n",
        "\n",
        "import_data()\n",
        "\n",
        "_ = !grep -Ril \"annotation\" {TARGET}/{IMAGES} | wc -l\n",
        "\n",
        "if int(_[0]) < 100:\n",
        "    raise SystemExit('''\n",
        "    Import your training data to {}/{} before continuing. \n",
        "    You should have at least 100 images for suitable training.\n",
        "    You may complete the `import_data()` function above to assist you to import your data. \n",
        "    '''.format(TARGET, IMAGES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MBfTBWpHxZr"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPvJOiuAqmgr"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sglvladi/TensorFlowObjectDetectionTutorial/725f22217178537030fde9492a7cdb0a7fff4d80/docs/source/scripts/partition_dataset.py -c       \n",
        "\n",
        "RANDOM_SEED = 10\n",
        "FRACTION_OF_TEST_DATA = 0.1\n",
        "\n",
        "from pyutil import filereplace\n",
        "filereplace(\"partition_dataset.py\", \"import random.*\", \"import random; random.seed({})\".format(RANDOM_SEED))\n",
        "\n",
        "!rm -rf {TARGET}/{IMAGES}/{TRAIN_DATA}/*\n",
        "!rm -rf {TARGET}/{IMAGES}/{TEST_DATA}/*\n",
        "!python partition_dataset.py -x -i {TARGET}/{IMAGES} -r {FRACTION_OF_TEST_DATA}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr-vYaxQsCnQ"
      },
      "source": [
        "def get_labels():\n",
        "    from xml.dom import minidom\n",
        "    import glob\n",
        "    objects = set()\n",
        "    xmls = glob.glob('{}/{}/*.xml'.format(TARGET,IMAGES))\n",
        "\n",
        "    for xml in xmls:\n",
        "        xmldoc = minidom.parse(xml)\n",
        "        itemlist = xmldoc.getElementsByTagName('name')\n",
        "        for item in itemlist:\n",
        "            objects.add(item.firstChild.nodeValue)\n",
        "    return objects\n",
        "\n",
        "def generate_labemlap():\n",
        "    global labels\n",
        "    \n",
        "    from IPython.core.getipython import get_ipython\n",
        "    shell = get_ipython()\n",
        "    content = \"%%writefile {TARGET}/{ANNOTATIONS}/{LABEL_MAP}\"\n",
        "    labels = list(get_labels())\n",
        "    for i in range(len(labels)):\n",
        "        content+='''\n",
        "item {{\n",
        "  id: {}\n",
        "  name: '{}'\n",
        "}}'''.format(i+1, labels[i])\n",
        "    content+=\"\\n\\n# generate_labemlap()\"\n",
        "    shell.set_next_input(content, replace=True)\n",
        "    print(\"# Template created. Re-run this code-cell to save your labelmap file\")\n",
        "    print(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOMJ6LVHP-qR"
      },
      "source": [
        "generate_labemlap()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGpRHCyFkJ_u"
      },
      "source": [
        "# Template created. Re-run this code-cell to save your labelmap file\n",
        "%%writefile {TARGET}/{ANNOTATIONS}/{LABEL_MAP}\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'Kraft zesty italian dressing'\n",
        "}\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'mustard'\n",
        "}\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'Pepsi tin'\n",
        "}\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'Apple'\n",
        "}\n",
        "item {\n",
        "  id: 5\n",
        "  name: 'Kraft ranch dressing'\n",
        "}\n",
        "item {\n",
        "  id: 6\n",
        "  name: 'Cocacola tin'\n",
        "}\n",
        "item {\n",
        "  id: 7\n",
        "  name: 'Hersheys choco syrup'\n",
        "}\n",
        "item {\n",
        "  id: 8\n",
        "  name: 'Hersheys strawberry flavoured syrup'\n",
        "}\n",
        "item {\n",
        "  id: 9\n",
        "  name: 'KitKat Milk Cocoa'\n",
        "}\n",
        "item {\n",
        "  id: 10\n",
        "  name: 'tomato_ketchup'\n",
        "}\n",
        "item {\n",
        "  id: 11\n",
        "  name: 'Kelloggs Corn Flakes'\n",
        "}\n",
        "item {\n",
        "  id: 12\n",
        "  name: 'Hersheys strawberry syrup'\n",
        "}\n",
        "item {\n",
        "  id: 13\n",
        "  name: 'Loreal Paris Fall Resist'\n",
        "}\n",
        "item {\n",
        "  id: 14\n",
        "  name: 'Kraft blue cheese dressing'\n",
        "}\n",
        "item {\n",
        "  id: 15\n",
        "  name: 'Tropicana Guava'\n",
        "}\n",
        "item {\n",
        "  id: 16\n",
        "  name: 'planters_cheezballs'\n",
        "}\n",
        "item {\n",
        "  id: 17\n",
        "  name: 'Pampers Pants'\n",
        "}\n",
        "item {\n",
        "  id: 18\n",
        "  name: 'Colgate Tooth Paste '\n",
        "}\n",
        "item {\n",
        "  id: 19\n",
        "  name: 'macaroni_cheese'\n",
        "}\n",
        "item {\n",
        "  id: 20\n",
        "  name: 'Hersheys caramel syrup'\n",
        "}\n",
        "item {\n",
        "  id: 21\n",
        "  name: 'Cheetos Crunchy'\n",
        "}\n",
        "item {\n",
        "  id: 22\n",
        "  name: 'Dr pepper tin'\n",
        "}\n",
        "item {\n",
        "  id: 23\n",
        "  name: 'Thumsup tin'\n",
        "}\n",
        "item {\n",
        "  id: 24\n",
        "  name: 'Nescafe Classic Coffee'\n",
        "}\n",
        "item {\n",
        "  id: 25\n",
        "  name: 'Colgate Tooth Paste'\n",
        "}\n",
        "\n",
        "# generate_labemlap()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sOKXrZispfC"
      },
      "source": [
        "!wget !wget https://raw.githubusercontent.com/sglvladi/TensorFlowObjectDetectionTutorial/725f22217178537030fde9492a7cdb0a7fff4d80/docs/source/scripts/generate_tfrecord.py -c     \n",
        "\n",
        "!python generate_tfrecord.py -x {TARGET}/{IMAGES}/{TRAIN_DATA} -l {TARGET}/{ANNOTATIONS}/{LABEL_MAP} -o {TARGET}/{ANNOTATIONS}/train.record\n",
        "!python generate_tfrecord.py -x {TARGET}/{IMAGES}/{TEST_DATA} -l {TARGET}/{ANNOTATIONS}/{LABEL_MAP} -o {TARGET}/{ANNOTATIONS}/test.record\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coH2J-cYkVdz"
      },
      "source": [
        "# Model Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1Hr0K3Lsujw"
      },
      "source": [
        "MODEL_NAME = MODEL_DOWNLOAD_LINK[MODEL_DOWNLOAD_LINK.rindex('/')+1:MODEL_DOWNLOAD_LINK.index('.tar.gz')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV2USDs6ubCM"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL_NAME}.tar.gz -P {PRETRAINED} -c\n",
        "!tar -zxvf {PRETRAINED}/{MODEL_NAME}.tar.gz -C {PRETRAINED}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxhcHyU8tuV5"
      },
      "source": [
        "# Pipeline Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jRiJuuOuhDN"
      },
      "source": [
        "!rm -rf {TARGET}/{MODELS}/{MODEL_NAME}/train\n",
        "\n",
        "!mkdir -p {TARGET}/{MODELS}/{MODEL_NAME}/\n",
        "!cp {PRETRAINED}/{MODEL_NAME}/pipeline.config {TARGET}/{MODELS}/{MODEL_NAME}/\n",
        "!cp {PRETRAINED}/{MODEL_NAME}/checkpoint/ckpt-0* {TARGET}/{MODELS}/{MODEL_NAME}/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ZA8L8pD1Y0"
      },
      "source": [
        "BATCH_SIZE = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSsVa7awGz3"
      },
      "source": [
        "import sys\n",
        "sys.path.append(TF_OD_PATH)\n",
        "\n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "\n",
        "with tf.io.gfile.GFile(\"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME), \"r\") as f:                                                                                                                                                                                                                                       \n",
        "    text_format.Merge(f.read(), pipeline_config)       \n",
        "\n",
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = BATCH_SIZE\n",
        "pipeline_config.train_config.fine_tune_checkpoint = \"\"+TARGET+\"/\"+MODELS+\"/\"+MODEL_NAME+\"/ckpt-0\"\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_config.use_bfloat16 = False\n",
        "pipeline_config.train_input_reader.label_map_path  = \"\"+TARGET+\"/annotations/label_map.pbtxt\"\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = \"\"+TARGET+\"/\"+ANNOTATIONS+\"/train.record\"   \n",
        "pipeline_config.eval_input_reader[0].label_map_path  = \"\"+TARGET+\"/annotations/label_map.pbtxt\"\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = \"\"+TARGET+\"/\"+ANNOTATIONS+\"/test.record\"                                                                                                                                                                                     \n",
        "                                                                                                                                                                                                         \n",
        "with tf.io.gfile.GFile(\"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME), \"wb\") as f:                                                                                                                                                                                                                       \n",
        "    f.write(text_format.MessageToString(pipeline_config)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZdfvic7sleJ"
      },
      "source": [
        "!pip install pyutil\n",
        "from pyutil import filereplace\n",
        "\n",
        "!cp {TF_OD_PATH}/object_detection/model_main_tf2.py .\n",
        "!cp {TF_OD_PATH}/object_detection/exporter_main_v2.py .\n",
        "\n",
        "filereplace(\"model_main_tf2.py\",\"FLAGS = flags.FLAGS\", \n",
        "'''flags.DEFINE_boolean('allow_growth', False,\n",
        "    ('Whether or not to limit gpu memory growth.'))\n",
        "    \n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "import sys\n",
        "from signal import signal, SIGPIPE, SIG_DFL \n",
        "\n",
        "def receiveSignal(signalNumber, frame):\n",
        "    print('Received:', signalNumber)\n",
        "    sys.exit(0)\n",
        "\n",
        "signal(SIGPIPE, receiveSignal)'''\n",
        "            \n",
        ")\n",
        "\n",
        "filereplace(\"model_main_tf2.py\",\"if FLAGS.checkpoint_dir:\",\n",
        "'''if FLAGS.allow_growth:\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "      try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "          tf.config.experimental.set_memory_growth(gpu, True)\n",
        "      except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        pass\n",
        "        \n",
        "  if FLAGS.checkpoint_dir:'''\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjhqMCVIt0Q2"
      },
      "source": [
        "# Training Schedule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "682JeGinqCxw"
      },
      "source": [
        "# MODEL_NAME = ??? \n",
        "\n",
        "if 'MODEL_NAME' not in vars():\n",
        "    MODEL_NAME = !ls -1 {TARGET}/{MODELS}/\n",
        "    if len(MODEL_NAME) != 1:\n",
        "        del MODEL_NAME\n",
        "        raise SystemExit('''\n",
        "Could not determine model name. Please specify above.\n",
        "        ''')\n",
        "    else:\n",
        "        MODEL_NAME = MODEL_NAME[0]\n",
        "\n",
        "MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJHdUrFXzp7M"
      },
      "source": [
        "!mkdir -p {TARGET}/{MODELS}/{MODEL_NAME}/train\n",
        "!mount -o bind /content/train/ {TARGET}/{MODELS}/{MODEL_NAME}/train\n",
        "!rm -rf /content/train/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evJ6Xk8517_U"
      },
      "source": [
        "!rm -rf /content/train/*\n",
        "!python -u model_main_tf2.py --model_dir={TARGET}/{MODELS}/{MODEL_NAME} \\\n",
        "--pipeline_config_path={TARGET}/{MODELS}/{MODEL_NAME}/pipeline.config \\\n",
        "--allow_growth 2>&1 | sed -e \"/loss=nan/q9\";echo $? > exitcode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdotsqMWM8oJ"
      },
      "source": [
        "# Checkpoint Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM_5EEsYeORs"
      },
      "source": [
        "# MODEL_NAME = ??? \n",
        "\n",
        "if 'MODEL_NAME' not in vars():\n",
        "    MODEL_NAME = !ls -1 {TARGET}/{MODELS}/\n",
        "    if len(MODEL_NAME) != 1:\n",
        "        del MODEL_NAME\n",
        "        raise SystemExit('''\n",
        "Could not determine model name. Please specify above.\n",
        "        ''')\n",
        "    else:\n",
        "        MODEL_NAME = MODEL_NAME[0]\n",
        "\n",
        "MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_D3_ijI2C3U"
      },
      "source": [
        "import sys\n",
        "sys.path.append(TF_OD_PATH)\n",
        "sys.path.append(TF_OD_PATH+'/../')\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "PATH_TO_CFG = \"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME)\n",
        "PATH_TO_CKPT = \"{}/{}/{}\".format(TARGET,MODELS,MODEL_NAME)\n",
        "\n",
        "print('Loading model... ', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore latest checkpoint\n",
        "latest = next(open(\"{}/{}/{}/checkpoint\".format(TARGET,MODELS,MODEL_NAME)))\n",
        "latest = latest[latest.index(\"\\\"\")+1:latest.rindex(\"\\\"\")]\n",
        "print(latest)\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(PATH_TO_CKPT, latest)).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LGDcXkzWSAf"
      },
      "source": [
        "PATH_TO_LABELS = \"{}/{}/{}\".format(TARGET,ANNOTATIONS,LABEL_MAP)\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOIXq3YVWW0V"
      },
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "def download_images():\n",
        "    base_url = 'file:///content/drive/MyDrive/colab/tf2-object-detection-trainer/{}/{}/'.format(TARGET,INFERENCE)\n",
        "    filenames = ['image_01.jpg']\n",
        "    image_paths = []\n",
        "    for filename in filenames:\n",
        "        image_path = tf.keras.utils.get_file(fname=filename,\n",
        "                                            origin=base_url + filename,\n",
        "                                            untar=False)\n",
        "        image_path = pathlib.Path(image_path)\n",
        "        image_paths.append(str(image_path))\n",
        "    return image_paths\n",
        "\n",
        "IMAGE_PATHS = download_images()\n",
        "print(IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHOkJMhIRlzM"
      },
      "source": [
        "!rm /root/.keras/datasets/image_01.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj238qUGmC1y"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "for image_path in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=200,\n",
        "            min_score_thresh=.30,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    \n",
        "    plt.imshow(image_np_with_detections)\n",
        "    \n",
        "    print('Done')\n",
        "plt.show()\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTXnls1fezFi"
      },
      "source": [
        "# Model Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gMG8LaLiPQ2"
      },
      "source": [
        "# MODEL_NAME = ??? \n",
        "\n",
        "if 'MODEL_NAME' not in vars():\n",
        "    MODEL_NAME = !ls -1 {TARGET}/{MODELS}/\n",
        "    if len(MODEL_NAME) != 1:\n",
        "        del MODEL_NAME\n",
        "        raise SystemExit('''\n",
        "Could not determine model name. Please specify above.\n",
        "        ''')\n",
        "    else:\n",
        "        MODEL_NAME = MODEL_NAME[0]\n",
        "\n",
        "MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYk2_lCafUn6"
      },
      "source": [
        "!python exporter_main_v2.py --input_type=image_tensor --pipeline_config_path={TARGET}/{MODELS}/{MODEL_NAME}/pipeline.config --trained_checkpoint_dir={TARGET}/{MODELS}/{MODEL_NAME} --output_directory={TARGET}/{EXPORTED}/{MODEL_NAME}\n",
        "!cp {TARGET}/{ANNOTATIONS}/{LABEL_MAP} {TARGET}/{EXPORTED}/{MODEL_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMginc7nT3mo"
      },
      "source": [
        "# Exported Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_9MKJ5wTbg2"
      },
      "source": [
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = \"{}/{}/{}/saved_model\".format(TARGET,EXPORTED,MODEL_NAME)\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bUgD6rYUJ6P"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "for image_path in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.5,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0nuR4KAWgZG"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5MesaPJQbe"
      },
      "source": [
        "%%javascript\n",
        "\n",
        "var startClickConnect = function startClickConnect(){\n",
        "    var clickConnect = function clickConnect(){\n",
        "        console.log(\"Connnect Clicked - Start\");\n",
        "        document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "        console.log(\"Connnect Clicked - End\"); \n",
        "    };\n",
        "\n",
        "    var intervalId = setInterval(clickConnect, 10000);\n",
        "\n",
        "    var stopClickConnectHandler = function stopClickConnect() {\n",
        "        console.log(\"Connnect Clicked Stopped - Start\");\n",
        "        clearInterval(intervalId);\n",
        "        console.log(\"Connnect Clicked Stopped - End\");\n",
        "    };\n",
        "\n",
        "    return stopClickConnectHandler;\n",
        "};\n",
        "\n",
        "var stopClickConnect = startClickConnect();\n",
        "\n",
        "//stopClickConnect();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
