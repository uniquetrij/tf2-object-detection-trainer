{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tensorflow-2 Object Detection Trainer](https://github.com/sglvladi/TensorFlowObjectDetectionTutorial/tree/725f22217178537030fde9492a7cdb0a7fff4d80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "We assume that this notebok will be run using __JupyterLab__ with __Anaconda__ environment on __Linux (Ubuntu)__ server. Although most part of it is independent of the above platform and frameworks, you may need to customize them a little to run on other environments.\n",
    "\n",
    "Installation of [JupyterLab](https://jupyter.org/) is simple. This notebook was tested on JupyterLab v3.0.9 and Python v3.8.5. You may use the following commands to install JupyterLab on a separate conda environment, say `jupyter-lab`,\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge jupyterlab=3.0\n",
    "```\n",
    "\n",
    "and to start JupyterLab, execute the following command.\n",
    "\n",
    "```bash\n",
    "jupyter lab --no-browser --ip=\"0.0.0.0\" --port=8989\n",
    "```\n",
    "\n",
    "We also assume that this notebook is placed at the root of your __tf2-object-detection-trainer__ project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup and Kernel Installation\n",
    "\n",
    "If you have not created a separate conda environment for your __tf2-object-detection-trainer__ project using this notebook, it is recommended that you create one now. The following code-cells automatically installs the required dependencies for your environment. If you already have an environment, you may skip this step and moce on to __\"Environment Switch\"__ section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Environment Name\n",
    "\n",
    "Set your preferred environment name below into the variable *`ENV_NAME`*, default is *`tf2-object-detection-trainer`*. This name will be used everywhere throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'tf2-object-detection-trainer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Your Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create --yes -n {ENV_NAME} pip python=3.8.5 jupyterlab=3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install iPython Kernel \n",
    "\n",
    "The following code cell will install your newly created conda environment as an iPython kernel to be used with Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "out = !conda env list | grep {ENV_NAME}\n",
    "env = out[0][out[0].index('/'):]\n",
    "\n",
    "!{env}/bin/python -m ipykernel install --prefix {sys.prefix} --name {ENV_NAME} --display-name {ENV_NAME}"
   ]
  },
  {
   "attachments": {
    "25996076-e36b-42fb-b83b-92f6cd2d6981.png": {
     "image/png": "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"
    },
    "7b461799-18ed-4e20-8e4a-537b4f607cba.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Switch\n",
    "\n",
    "Now that your kernel is instaled, you'll need to change your Jupyter Notebook's python environment (kernel) to the one that you have created. You'll find the option to switch kernel on top-right of your notebook.\n",
    "\n",
    "<div><img src=\"attachment:25996076-e36b-42fb-b83b-92f6cd2d6981.png\" width=\"150\"></div>\n",
    "<div><img src=\"attachment:7b461799-18ed-4e20-8e4a-537b4f607cba.png\" width=\"150\"/></div>\n",
    "\n",
    "If you don't find your environment in the dropdown, try refreshing/restarting your Jupyter server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that you have successfully switched your kernel by the following code cell. It should print the *`ENV_NAME`* you had built earlier. If it prints something else, then the kernel switch wasn't successful. Fix it before proceeding further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "ENV_NAME = sys.prefix\n",
    "ENV_NAME = ENV_NAME[ENV_NAME.rindex('/')+1:]\n",
    "\n",
    "ENV_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection API Installation\n",
    "\n",
    "Now that we have our environment ready, lets clone the *`tensorflow/models`* github repository. We'll switch to commit *`73ce096`* to so that our code doesn't break dur to subsequent updates in the repository. We'll put the cloned repo in a folder named *`tensorflow`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf tensorflow\n",
    "!git clone https://github.com/tensorflow/models tensorflow/models 2> /dev/null\n",
    "!(cd tensorflow/models;git checkout 73ce096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProtocolBuffer Installation\n",
    "\n",
    "Now lets download and extract protobuf v3.13.0 into a folder named *`protoc`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/protocolbuffers/protobuf/releases/download/v3.13.0/protoc-3.13.0-linux-x86_64.zip -c\n",
    "!unzip protoc-3.13.0-linux-x86_64.zip -d protoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll install protoc into *`tensorflow/models/research`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ as export\n",
    "\n",
    "pwd = !pwd\n",
    "export['PATH'] += ':' + pwd[0] + '/protoc/bin'\n",
    "!(cd tensorflow/models/research;protoc object_detection/protos/*.proto --python_out=.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Dependency Installation\n",
    "\n",
    "We will install all required python dependencies directly from this notebook. For this, we'll need a reference to the python executable of our conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import executable as python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing GPU Version\n",
    "\n",
    "We'll install TensorFlow-GPU version 2.4 and its dependency CUDAToolkit version 11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda install --yes --prefix {sys.prefix} -c anaconda cudatoolkit=11.0 absl-py=0.10\n",
    "!{python} -m pip install tensorflow-gpu==2.4 python-util==1.2.1 absl-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cuDNN-8 Installation\n",
    "\n",
    "At the time of writing this script, Anaconda's cudatoolkit-11 does not automatically install cuDNN-8. Hence you'll need to install it manually.\n",
    "Download cuDNN-8 packages from [here](https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.1.0.77/11.2_20210127/cudnn-11.2-linux-x64-v8.1.0.77.tgz) and place it into your project's root. Once done, execute the following code-cell to set it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir cuDNN8\n",
    "!tar -xzvf cudnn-11.2-linux-x64-v8.1.0.77.tgz -C cuDNN8\n",
    "!chmod a+x cuDNN8/cuda/include/cudnn*.h cuDNN8/cuda/lib64/libcudnn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Non-GPU Version\n",
    "\n",
    "Install TensorFlow version 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{python} -m pip install tensorflow==2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Installation Of Other Dependencies\n",
    "\n",
    "Run the following code-cell to automatically install all other python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp tensorflow/models/research/object_detection/packages/tf2/setup.py tensorflow/models/research/\n",
    "!{python} -m pip install tensorflow/models/research/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Installation of Dependencies (Only if automatic installation fails)\n",
    "\n",
    "Run the following code-cell to manually install all other python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{python} -m pip install tf_slim==1.1.0 matplotlib==3.3.4 lvis==0.5.3 scipy==1.6.1 pyyaml==5.4.1 gin-config==0.4.0 tensorflow-addons==0.12.1 pandas==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Installed Packages\n",
    "\n",
    "You can use the following code-cell to list all dependencies in your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!conda list --prefix {sys.prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninstalling Dependencies\n",
    "\n",
    "If you ever want to remove a python package, you can use the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{python} -m pip uninstall -y tf_slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyCOCOTools Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cocodataset/cocoapi.git cocoapi 2> /dev/null\n",
    "!(cd cocoapi;git checkout 8c9bcc3)\n",
    "\n",
    "!conda install --yes --prefix {sys.prefix} cython\n",
    "!(cd cocoapi/PythonAPI/; printf 'conda activate {ENV_NAME}\\nmake\\n' | bash -i )\n",
    "\n",
    "!cp -r ./cocoapi/PythonAPI/pycocotools ./tensorflow/models/research/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuDNN Reference for GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ as export\n",
    "export['LD_LIBRARY_PATH']='cuDNN8/cuda/lib64/:'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "If the below code runs successfully, you have your environment ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your setup is complete. Now you can start your training below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Delete Environment and Remove Kernel\n",
    "\n",
    "If you want to delete kernels and conda environments from this notebook, you may use the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'tf2-object-detection-trainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda remove --yes --name {ENV_NAME} --all\n",
    "!rm -rf {sys.prefix}/share/jupyter/kernels/{ENV_NAME}\n",
    "!yes | jupyter kernelspec remove {ENV_NAME} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda clean --yes --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter kernelspec list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "We assume that this will be run using __JupyterLab__ with __Anaconda__ environment on __Linux (Ubuntu 18.04)__ server. Although most part of it is independent of the above platform and frameworks, you may need to customize them to run on other environments.\n",
    "\n",
    "At this point you should already have your data/images labeled/annotated. This script only helps in starting the model training pipeline and doesn't involve data annotation. For getting your images annotated, you may use [LabelImg](https://github.com/tzutalin/labelImg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that you using the correct kernel for your object detection pipeline. The following code-cell should print the ENV_NAME you had built earlier using the [setup.ipynb](../setup.ipynb). If it prints something else, switch your kernel to the desired one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "%mkdir -p targets\n",
    "%cd targets\n",
    "\n",
    "ENV_NAME = sys.prefix\n",
    "ENV_NAME = ENV_NAME[ENV_NAME.rindex('/')+1:]\n",
    "\n",
    "ENV_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Selection And Project Structure\n",
    "\n",
    "Select your target folder for your object detection training project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'pepsico-detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Your Project Structure\n",
    "\n",
    "Below is the default names of the folders inside your project folder. You may leave them as is. This script automatically builds the project structure for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS = 'annotations'\n",
    "EXPORTED = 'exported-models'\n",
    "IMAGES = 'images'\n",
    "TEST_DATA = 'test'\n",
    "TRAIN_DATA = 'train'\n",
    "LABEL_MAP = 'label_map.pbtxt'\n",
    "MODELS = 'models'\n",
    "INFERENCE = 'inference'\n",
    "PRETRAINED = '.pre-trained-models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {TARGET}/{IMAGES}/{TEST_DATA}\n",
    "!mkdir -p {TARGET}/{IMAGES}/{TRAIN_DATA}\n",
    "!mkdir -p {TARGET}/{ANNOTATIONS}\n",
    "!mkdir -p {TARGET}/{EXPORTED}\n",
    "!mkdir -p {TARGET}/{MODELS}\n",
    "!mkdir -p {TARGET}/{INFERENCE}\n",
    "!mkdir -p {PRETRAINED}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll set reference to tensorflow's `objec-detection` folder's parent in the variable *`TF_OD_PATH`*. If you are following the instructions of these scripts it should be *`../tensorflow/models/research`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_OD_PATH = '../tensorflow/models/research'\n",
    "\n",
    "import sys\n",
    "from sys import executable as python\n",
    "from os import environ as export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Images and Labels\n",
    "\n",
    "You'll need to manually copy your images and labels into the `images` folder of your target project. You need not split your data manually. The following code section does that for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/sglvladi/TensorFlowObjectDetectionTutorial/725f22217178537030fde9492a7cdb0a7fff4d80/docs/source/scripts/partition_dataset.py -c       \n",
    "\n",
    "FRACTION_OF_TEST_DATA = 0.1\n",
    "\n",
    "!{python} partition_dataset.py -x -i {TARGET}/{IMAGES} -r {FRACTION_OF_TEST_DATA}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Your Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    from xml.dom import minidom\n",
    "    import glob\n",
    "    objects = set()\n",
    "    xmls = glob.glob('{}/{}/*.xml'.format(TARGET,IMAGES))\n",
    "\n",
    "    for xml in xmls:\n",
    "        xmldoc = minidom.parse(xml)\n",
    "        itemlist = xmldoc.getElementsByTagName('name')\n",
    "        for item in itemlist:\n",
    "            objects.add(item.firstChild.nodeValue)\n",
    "    return objects\n",
    "\n",
    "def generate_labemlap():\n",
    "    global labels\n",
    "    \n",
    "    from IPython.core.getipython import get_ipython\n",
    "    shell = get_ipython()\n",
    "    content = \"%%writefile {TARGET}/{ANNOTATIONS}/{LABEL_MAP}\"\n",
    "    labels = list(get_labels())\n",
    "    for i in range(len(labels)):\n",
    "        content+='''\n",
    "item {{\n",
    "  id: {}\n",
    "  name: '{}'\n",
    "}}'''.format(i+1, labels[i])\n",
    "    content+=\"\\n\\n# generate_labemlap()\"\n",
    "    shell.set_next_input(content, replace=True)\n",
    "    print(\"Template created. Re-run this code-cell to save your labelmap file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following code-cell will create the basic template of your label map for you to edit. Once done, re-run the cell to save the labelmap file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_labemlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Tensorflow's *`models`* and *`research`* packages to your *`PYTHONPATH`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export['PYTHONPATH']=TF_OD_PATH+'/models/research/:' \n",
    "export['PYTHONPATH']+=TF_OD_PATH+'/:'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate TF-Record files from out annotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/sglvladi/TensorFlowObjectDetectionTutorial/725f22217178537030fde9492a7cdb0a7fff4d80/docs/source/scripts/generate_tfrecord.py -c     \n",
    "\n",
    "!{python} generate_tfrecord.py -x {TARGET}/{IMAGES}/{TRAIN_DATA} -l {TARGET}/{ANNOTATIONS}/{LABEL_MAP} -o {TARGET}/{ANNOTATIONS}/train.record\n",
    "\n",
    "!{python} generate_tfrecord.py -x {TARGET}/{IMAGES}/{TEST_DATA} -l {TARGET}/{ANNOTATIONS}/{LABEL_MAP} -o {TARGET}/{ANNOTATIONS}/test.record\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Model Zoo\n",
    "Download your desired model from Tensorflow's [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). For this, you can set the variable *`MODEL_DOWNLOAD_LINK`* to the download link of the model file (.tar.gz) or you can directly set the model name (name of the .tar.gz) in the variable *`MODEL_NAME`*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DOWNLOAD_LINK = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\"\n",
    "MODEL_NAME = MODEL_DOWNLOAD_LINK[MODEL_DOWNLOAD_LINK.rindex('/')+1:MODEL_DOWNLOAD_LINK.index('.tar.gz')]\n",
    "\n",
    "## OR\n",
    "\n",
    "# MODEL_NAME = \"efficientdet_d1_coco17_tpu-32\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code-cell downloads the model from tensorflow's model zoo and extracts into a PRETRAINED folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL_NAME}.tar.gz -P {PRETRAINED} -c\n",
    "!tar -zxvf {PRETRAINED}/{MODEL_NAME}.tar.gz -C {PRETRAINED}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model\n",
    "\n",
    "If you want to use a custom model as your pretrained model, make sure to put it into the pretrained folder with proper checkpoints following the same folder structure as models from Tensorflow Model Zoo. Here *`MODEL_NAME`* is the name of the folder containing your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'efficientdet_d1_coco17_tpu-32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Available Models\n",
    "\n",
    "You can display a list of all pretrained models in your PRETRAINED folder using the following code-cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PRETRAINED} -I \"*.tar*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Your Training Config Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required directories and import the `model-checkpoint` and the `configuration-pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {TARGET}/{MODELS}/{MODEL_NAME}/\n",
    "!cp {PRETRAINED}/{MODEL_NAME}/pipeline.config {TARGET}/{MODELS}/{MODEL_NAME}/\n",
    "!cp {PRETRAINED}/{MODEL_NAME}/checkpoint/ckpt-0* {TARGET}/{MODELS}/{MODEL_NAME}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Update Your Configuration Pipeline\n",
    "\n",
    "Select your batch size as per your system's capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code-cell automatically updates your `configuration-pipeline`. You need not modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(TF_OD_PATH)\n",
    "\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "from object_detection.protos import pipeline_pb2\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
    "\n",
    "with tf.io.gfile.GFile(\"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME), \"r\") as f:                                                                                                                                                                                                                                       \n",
    "    text_format.Merge(f.read(), pipeline_config)       \n",
    "\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = BATCH_SIZE\n",
    "pipeline_config.train_config.fine_tune_checkpoint = \"\"+TARGET+\"/\"+MODELS+\"/\"+MODEL_NAME+\"/ckpt-0\"\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_config.use_bfloat16 = False\n",
    "pipeline_config.train_input_reader.label_map_path  = \"\"+TARGET+\"/annotations/label_map.pbtxt\"\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = \"\"+TARGET+\"/\"+ANNOTATIONS+\"/train.record\"   \n",
    "pipeline_config.eval_input_reader[0].label_map_path  = \"\"+TARGET+\"/annotations/label_map.pbtxt\"\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = \"\"+TARGET+\"/\"+ANNOTATIONS+\"/test.record\"                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                         \n",
    "with tf.io.gfile.GFile(\"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME), \"wb\") as f:                                                                                                                                                                                                                       \n",
    "    f.write(text_format.MessageToString(pipeline_config)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyutil import filereplace\n",
    "\n",
    "# for k,v in {\n",
    "    \n",
    "# \"num_classes:.*\": \"num_classes: {} # Set this to the number of different label classes\".format(len(labels)),\n",
    "\n",
    "# \"batch_size: 128\": \"batch_size: {} # Increase/Decrease this value depending on the available memory (Higher values require more memory and vice-versa)\".format(BATCH_SIZE),\n",
    "\n",
    "# \"fine_tune_checkpoint:.*\": \"fine_tune_checkpoint: \\\"\"+PRETRAINED+\"/\"+MODEL_NAME+\"/checkpoint/ckpt-0\\\" # Path to checkpoint of pre-trained model\",\n",
    "\n",
    "# \"fine_tune_checkpoint_type:.*\": \"fine_tune_checkpoint_type: \\\"detection\\\" # Set this to \\\"detection\\\" since we want to be training the full detection mode\",\n",
    "\n",
    "# \"use_bfloat16:.*\": \"use_bfloat16: false # Set this to false if you are not training on a TPU\",\n",
    "\n",
    "# \"label_map_path:.*\": \"label_map_path: \\\"\"+TARGET+\"/annotations/label_map.pbtxt\\\" # Path to label map file\",\n",
    "    \n",
    "# \"input_path:.*train.*\": \"input_path: \\\"\"+TARGET+\"/\"+ANNOTATIONS+\"/train.record\\\" # Path to testing TFRecord file\\n\",\n",
    "\n",
    "# \"input_path:.*val.*\": \"input_path: \\\"\"+TARGET+\"/\"+ANNOTATIONS+\"/test.record\\\" # Path to testing TFRecord file\\n\"\n",
    "\n",
    "# }.items():filereplace(\"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME),k, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy model trainer script from tensorflow's `object_detection` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds options to enable memory-growth while using GPU for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyutil\n",
    "from pyutil import filereplace\n",
    "\n",
    "!cp {TF_OD_PATH}/object_detection/model_main_tf2.py .\n",
    "!cp {TF_OD_PATH}/object_detection/exporter_main_v2.py .\n",
    "\n",
    "filereplace(\"model_main_tf2.py\",\"FLAGS = flags.FLAGS\", \n",
    "'''flags.DEFINE_boolean('allow_growth', False,\n",
    "    ('Whether or not to limit gpu memory growth.'))\n",
    "    \n",
    "FLAGS = flags.FLAGS'''\n",
    ")\n",
    "\n",
    "filereplace(\"model_main_tf2.py\",\"if FLAGS.checkpoint_dir:\",\n",
    "'''if FLAGS.allow_growth:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        pass\n",
    "        \n",
    "  if FLAGS.checkpoint_dir:'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuDNN Reference for GPU \n",
    "\n",
    "Set reference to your cuDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "export['LD_LIBRARY_PATH']='../cuDNN8/cuda/lib64/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Script\n",
    "\n",
    "Finally launch your training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {TARGET}/{MODELS}/{MODEL_NAME}/train\n",
    "!{python} -u model_main_tf2.py --model_dir={TARGET}/{MODELS}/{MODEL_NAME} --pipeline_config_path={TARGET}/{MODELS}/{MODEL_NAME}/pipeline.config --allow_growth | sed -e '/loss=nan/q'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = ??? \n",
    "\n",
    "if 'MODEL_NAME' not in vars():\n",
    "    MODEL_NAME = !ls -1 {TARGET}/{MODELS}/\n",
    "    if len(MODEL_NAME) != 1:\n",
    "        del MODEL_NAME\n",
    "        raise SystemExit('''\n",
    "Could not determine model name. Please specify above.\n",
    "        ''')\n",
    "    else:\n",
    "        MODEL_NAME = MODEL_NAME[0]\n",
    "\n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(TF_OD_PATH)\n",
    "sys.path.append(TF_OD_PATH+'/../')\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "PATH_TO_CFG = \"{}/{}/{}/pipeline.config\".format(TARGET,MODELS,MODEL_NAME)\n",
    "PATH_TO_CKPT = \"{}/{}/{}\".format(TARGET,MODELS,MODEL_NAME)\n",
    "\n",
    "print('Loading model... ', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore latest checkpoint\n",
    "latest = next(open(\"{}/{}/{}/checkpoint\".format(TARGET,MODELS,MODEL_NAME)))\n",
    "latest = latest[latest.index(\"\\\"\")+1:latest.rindex(\"\\\"\")]\n",
    "print(latest)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, latest)).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = \"{}/{}/{}\".format(TARGET,ANNOTATIONS,LABEL_MAP)\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "def download_images():\n",
    "    base_url = 'file:///home/uniquetrij/Projects/jupyter-lab/tf2-object-detection-trainer/targets/{}/inference/'.format(TARGET)\n",
    "    filenames = ['image_01.jpg','image_02.jpg','image_03.jpg']\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "        image_path = tf.keras.utils.get_file(fname=filename,\n",
    "                                            origin=base_url + filename,\n",
    "                                            untar=False)\n",
    "        image_path = pathlib.Path(image_path)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths\n",
    "\n",
    "IMAGE_PATHS = download_images()\n",
    "print(IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.5,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    plt.imshow(image_np_with_detections)\n",
    "    \n",
    "    print('Done')\n",
    "plt.show()\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = ??? \n",
    "\n",
    "if 'MODEL_NAME' not in vars():\n",
    "    MODEL_NAME = !ls -1 {TARGET}/{MODELS}/\n",
    "    if len(MODEL_NAME) != 1:\n",
    "        del MODEL_NAME\n",
    "        raise SystemExit('''\n",
    "Could not determine model name. Please specify above.\n",
    "        ''')\n",
    "    else:\n",
    "        MODEL_NAME = MODEL_NAME[0]\n",
    "\n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{python} exporter_main_v2.py --input_type=image_tensor --pipeline_config_path={TARGET}/{MODELS}/{MODEL_NAME}/pipeline.config --trained_checkpoint_dir={TARGET}/{MODELS}/{MODEL_NAME} --output_directory={TARGET}/{EXPORTED}/{MODEL_NAME}\n",
    "!cp {TARGET}/{ANNOTATIONS}/{LABEL_MAP} {TARGET}/{EXPORTED}/{MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exported Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL = \"{}/{}/{}/saved_model\".format(TARGET,EXPORTED,MODEL_NAME)\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.5,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print('Done')\n",
    "plt.show()\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
